{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4105fa76-14b3-4cf1-88c5-631262e72bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
      "0                 0.07871  ...         25.38          17.33           184.60   \n",
      "1                 0.05667  ...         24.99          23.41           158.80   \n",
      "2                 0.05999  ...         23.57          25.53           152.50   \n",
      "3                 0.09744  ...         14.91          26.50            98.87   \n",
      "4                 0.05883  ...         22.54          16.67           152.20   \n",
      "\n",
      "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   worst concave points  worst symmetry  worst fractal dimension  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)  # Features\n",
    "y = pd.Series(data.target)  \n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73eae217-0b82-400a-8b8e-a571df515f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "515ed0b0-2bca-473b-9d75-837b1df3da33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train the model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = log_reg.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fc3866b-609b-4ed1-8256-798046e3d0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9415204678362573\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = dtree.predict(X_test)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c738e35-8ae3-4fd5-8eb8-b440eaccafb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9707602339181286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed2cbe4f-2de1-452c-919f-d861224108cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9766081871345029\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the model\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = svm.predict(X_test)\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eef8adef-5d7a-41a7-b210-bd0c187e8826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Accuracy: 0.9590643274853801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"k-NN Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61cac7d6-fe35-40a0-b9d4-07bbad862e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison (Accuracy):\n",
      "Logistic Regression: 0.9825\n",
      "Decision Tree: 0.9415\n",
      "Random Forest: 0.9708\n",
      "SVM: 0.9766\n",
      "k-NN: 0.9591\n",
      "\n",
      "Best Performing Model: Logistic Regression with accuracy 0.9825\n",
      "Worst Performing Model: Decision Tree with accuracy 0.9415\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    y_pred = model.predict(X_test)  # Make predictions\n",
    "    accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy\n",
    "    results[name] = accuracy  # Store the accuracy\n",
    "\n",
    "# Display the results\n",
    "print(\"Model Comparison (Accuracy):\")\n",
    "for name, accuracy in results.items():\n",
    "    print(f\"{name}: {accuracy:.4f}\")\n",
    "\n",
    "# Determine the best and worst performing models\n",
    "best_model = max(results, key=results.get)\n",
    "worst_model = min(results, key=results.get)\n",
    "print(f\"\\nBest Performing Model: {best_model} with accuracy {results[best_model]:.4f}\")\n",
    "print(f\"Worst Performing Model: {worst_model} with accuracy {results[worst_model]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc5e385-05da-4f16-b83e-95650926d637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
